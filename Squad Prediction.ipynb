{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import tokenization\n",
    "import six\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import tf_utils\n",
    "from albert import AlbertConfig, AlbertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALBertQALayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Layer computing position and is_possible for question answering task.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, start_n_top, end_n_top, initializer, dropout, **kwargs):\n",
    "        \"\"\"Constructs Summarization layer.\n",
    "        Args:\n",
    "          hidden_size: Int, the hidden size.\n",
    "          start_n_top: Beam size for span start.\n",
    "          end_n_top: Beam size for span end.\n",
    "          initializer: Initializer used for parameters.\n",
    "          dropout: float, dropout rate.\n",
    "          **kwargs: Other parameters.\n",
    "        \"\"\"\n",
    "        super(ALBertQALayer, self).__init__(**kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.start_n_top = start_n_top\n",
    "        self.end_n_top = end_n_top\n",
    "        self.initializer = initializer\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def build(self, unused_input_shapes):\n",
    "        \"\"\"Implements build() for the layer.\"\"\"\n",
    "        self.start_logits_proj_layer = tf.keras.layers.Dense(\n",
    "            units=1, kernel_initializer=self.initializer, name='start_logits/dense')\n",
    "        self.end_logits_proj_layer0 = tf.keras.layers.Dense(\n",
    "            units=self.hidden_size,\n",
    "            kernel_initializer=self.initializer,\n",
    "            activation=tf.nn.tanh,\n",
    "            name='end_logits/dense_0')\n",
    "        self.end_logits_proj_layer1 = tf.keras.layers.Dense(\n",
    "            units=1, kernel_initializer=self.initializer, name='end_logits/dense_1')\n",
    "        self.end_logits_layer_norm = tf.keras.layers.LayerNormalization(\n",
    "            axis=-1, epsilon=1e-12, name='end_logits/LayerNorm')\n",
    "        self.answer_class_proj_layer0 = tf.keras.layers.Dense(\n",
    "            units=self.hidden_size,\n",
    "            kernel_initializer=self.initializer,\n",
    "            activation=tf.nn.tanh,\n",
    "            name='answer_class/dense_0')\n",
    "        self.answer_class_proj_layer1 = tf.keras.layers.Dense(\n",
    "            units=1,\n",
    "            kernel_initializer=self.initializer,\n",
    "            use_bias=False,\n",
    "            name='answer_class/dense_1')\n",
    "        self.ans_feature_dropout = tf.keras.layers.Dropout(rate=self.dropout)\n",
    "        super(ALBertQALayer, self).build(unused_input_shapes)\n",
    "\n",
    "    def __call__(self,\n",
    "                 sequence_output,\n",
    "                 p_mask,\n",
    "                 cls_index,\n",
    "                 start_positions=None,\n",
    "                 **kwargs):\n",
    "        inputs = tf_utils.pack_inputs(\n",
    "            [sequence_output, p_mask, cls_index, start_positions])\n",
    "        return super(ALBertQALayer, self).__call__(inputs, **kwargs)\n",
    "\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\"Implements call() for the layer.\"\"\"\n",
    "        unpacked_inputs = tf_utils.unpack_inputs(inputs)\n",
    "        sequence_output = unpacked_inputs[0]\n",
    "        p_mask = unpacked_inputs[1]\n",
    "        cls_index = unpacked_inputs[2]\n",
    "        start_positions = unpacked_inputs[3]\n",
    "\n",
    "        _, seq_len, _ = sequence_output.shape.as_list()\n",
    "        sequence_output = tf.transpose(sequence_output, [1, 0, 2])\n",
    "\n",
    "        start_logits = self.start_logits_proj_layer(sequence_output)\n",
    "        start_logits = tf.transpose(tf.squeeze(start_logits, -1), [1, 0])\n",
    "        start_logits_masked = start_logits * (1 - p_mask) - 1e30 * p_mask\n",
    "        start_log_probs = tf.nn.log_softmax(start_logits_masked, -1)\n",
    "\n",
    "        if kwargs.get(\"training\", False):\n",
    "            # during training, compute the end logits based on the\n",
    "            # ground truth of the start position\n",
    "            start_positions = tf.reshape(start_positions, [-1])\n",
    "            start_index = tf.one_hot(start_positions, depth=seq_len, axis=-1,\n",
    "                                     dtype=tf.float32)\n",
    "            start_features = tf.einsum(\n",
    "                'lbh,bl->bh', sequence_output, start_index)\n",
    "            start_features = tf.tile(start_features[None], [seq_len, 1, 1])\n",
    "            end_logits = self.end_logits_proj_layer0(\n",
    "                tf.concat([sequence_output, start_features], axis=-1))\n",
    "\n",
    "            end_logits = self.end_logits_layer_norm(end_logits)\n",
    "\n",
    "            end_logits = self.end_logits_proj_layer1(end_logits)\n",
    "            end_logits = tf.transpose(tf.squeeze(end_logits, -1), [1, 0])\n",
    "            end_logits_masked = end_logits * (1 - p_mask) - 1e30 * p_mask\n",
    "            end_log_probs = tf.nn.log_softmax(end_logits_masked, -1)\n",
    "        else:\n",
    "            start_top_log_probs, start_top_index = tf.nn.top_k(\n",
    "                start_log_probs, k=self.start_n_top)\n",
    "            start_index = tf.one_hot(\n",
    "                start_top_index, depth=seq_len, axis=-1, dtype=tf.float32)\n",
    "            start_features = tf.einsum(\n",
    "                'lbh,bkl->bkh', sequence_output, start_index)\n",
    "            end_input = tf.tile(sequence_output[:, :, None], [\n",
    "                                1, 1, self.start_n_top, 1])\n",
    "            start_features = tf.tile(start_features[None], [seq_len, 1, 1, 1])\n",
    "            end_input = tf.concat([end_input, start_features], axis=-1)\n",
    "            end_logits = self.end_logits_proj_layer0(end_input)\n",
    "            end_logits = tf.reshape(end_logits, [seq_len, -1, self.hidden_size])\n",
    "            end_logits = self.end_logits_layer_norm(end_logits)\n",
    "\n",
    "            end_logits = tf.reshape(end_logits,\n",
    "                                    [seq_len, -1, self.start_n_top, self.hidden_size])\n",
    "\n",
    "            end_logits = self.end_logits_proj_layer1(end_logits)\n",
    "            end_logits = tf.reshape(\n",
    "                end_logits, [seq_len, -1, self.start_n_top])\n",
    "            end_logits = tf.transpose(end_logits, [1, 2, 0])\n",
    "            end_logits_masked = end_logits * (\n",
    "                1 - p_mask[:, None]) - 1e30 * p_mask[:, None]\n",
    "            end_log_probs = tf.nn.log_softmax(end_logits_masked, -1)\n",
    "            end_top_log_probs, end_top_index = tf.nn.top_k(\n",
    "                end_log_probs, k=self.end_n_top)\n",
    "            end_top_log_probs = tf.reshape(end_top_log_probs,\n",
    "                                           [-1, self.start_n_top * self.end_n_top])\n",
    "            end_top_index = tf.reshape(end_top_index,\n",
    "                                       [-1, self.start_n_top * self.end_n_top])\n",
    "\n",
    "        # an additional layer to predict answerability\n",
    "\n",
    "        # get the representation of CLS\n",
    "        cls_index = tf.one_hot(cls_index, seq_len, axis=-1, dtype=tf.float32)\n",
    "        cls_feature = tf.einsum('lbh,bl->bh', sequence_output, cls_index)\n",
    "\n",
    "        # get the representation of START\n",
    "        start_p = tf.nn.softmax(start_logits_masked,\n",
    "                                axis=-1, name='softmax_start')\n",
    "        start_feature = tf.einsum('lbh,bl->bh', sequence_output, start_p)\n",
    "\n",
    "        ans_feature = tf.concat([start_feature, cls_feature], -1)\n",
    "        ans_feature = self.answer_class_proj_layer0(ans_feature)\n",
    "        ans_feature = self.ans_feature_dropout(\n",
    "            ans_feature, training=kwargs.get('training', False))\n",
    "        cls_logits = self.answer_class_proj_layer1(ans_feature)\n",
    "        cls_logits = tf.squeeze(cls_logits, -1)\n",
    "\n",
    "        if kwargs.get(\"training\", False):\n",
    "            return (start_log_probs, end_log_probs, cls_logits)\n",
    "        else:\n",
    "            return (start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits)\n",
    "\n",
    "\n",
    "class ALBertQAModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, albert_config, max_seq_length, init_checkpoint, start_n_top, end_n_top, dropout=0.1, **kwargs):\n",
    "        super(ALBertQAModel, self).__init__(**kwargs)\n",
    "        self.albert_config = copy.deepcopy(albert_config)\n",
    "        self.initializer = tf.keras.initializers.TruncatedNormal(\n",
    "            stddev=self.albert_config.initializer_range)\n",
    "        float_type = tf.float32\n",
    "\n",
    "        input_word_ids = tf.keras.layers.Input(\n",
    "            shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')\n",
    "        input_mask = tf.keras.layers.Input(\n",
    "            shape=(max_seq_length,), dtype=tf.int32, name='input_mask')\n",
    "        input_type_ids = tf.keras.layers.Input(\n",
    "            shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')\n",
    "\n",
    "        albert_layer = AlbertModel(config=albert_config, float_type=float_type)\n",
    "\n",
    "        _, sequence_output = albert_layer(\n",
    "            input_word_ids, input_mask, input_type_ids)\n",
    "\n",
    "        self.albert_model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids],\n",
    "                                           outputs=[sequence_output])\n",
    "        if init_checkpoint != None:\n",
    "            self.albert_model.load_weights(init_checkpoint)\n",
    "\n",
    "        self.qalayer = ALBertQALayer(self.albert_config.hidden_size, start_n_top, end_n_top,\n",
    "                                     self.initializer, dropout)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # unpacked_inputs = tf_utils.unpack_inputs(inputs)\n",
    "        unique_ids = inputs[\"unique_ids\"]\n",
    "        input_word_ids = inputs[\"input_ids\"]\n",
    "        input_mask = inputs[\"input_mask\"]\n",
    "        segment_ids = inputs[\"segment_ids\"]\n",
    "        cls_index = tf.reshape(inputs[\"cls_index\"], [-1])\n",
    "        p_mask = inputs[\"p_mask\"]\n",
    "        if kwargs.get('training',False):\n",
    "            start_positions = inputs[\"start_positions\"]\n",
    "        else:\n",
    "            start_positions = None\n",
    "        sequence_output = self.albert_model(\n",
    "            [input_word_ids, input_mask, segment_ids], **kwargs)\n",
    "        output = self.qalayer(\n",
    "            sequence_output, p_mask, cls_index, start_positions, **kwargs)\n",
    "        return (unique_ids,) + output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_lower_case = True\n",
    "albert_config_file = \"xxlarge/config.json\"\n",
    "spm_model_file = \"xxlarge/vocab/30k-clean.model\"\n",
    "max_seq_length = 384\n",
    "null_score_diff_threshold = 0.0\n",
    "\n",
    "model_dir = \"squad_out_v2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can have documents that are longer than the maximum sequence length.\n",
    "    # To deal with this we do a sliding window approach, where we take chunks\n",
    "    # of the up to our max length with a stride of `doc_stride`.\n",
    "_DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "            \"DocSpan\", [\"start\", \"length\"])\n",
    "\n",
    "RawResultV2 = collections.namedtuple(\n",
    "    \"RawResultV2\",\n",
    "    [\"unique_id\", \"start_top_log_probs\", \"start_top_index\",\n",
    "     \"end_top_log_probs\", \"end_top_index\", \"cls_logits\"])\n",
    "\n",
    "_PrelimPredictionV2 = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "    \"PrelimPrediction\",\n",
    "    [\"feature_index\", \"start_index\", \"end_index\",\n",
    "     \"start_log_prob\", \"end_log_prob\"])\n",
    "\n",
    "_NbestPredictionV2 = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "    \"NbestPrediction\", [\"text\", \"start_log_prob\", \"end_log_prob\",\"start_index\",\"end_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\n",
    "      vocab_file=None,spm_model_file=spm_model_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadExample(object):\n",
    "  \"\"\"A single training/test example for simple sequence classification.\n",
    "     For examples without an answer, the start and end position are -1.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               qas_id,\n",
    "               question_text,\n",
    "               paragraph_text,\n",
    "               orig_answer_text=None,\n",
    "               start_position=None,\n",
    "               end_position=None,\n",
    "               is_impossible=False):\n",
    "    self.qas_id = qas_id\n",
    "    self.question_text = question_text\n",
    "    self.paragraph_text = paragraph_text\n",
    "    self.orig_answer_text = orig_answer_text\n",
    "    self.start_position = start_position\n",
    "    self.end_position = end_position\n",
    "    self.is_impossible = is_impossible\n",
    "\n",
    "  def __str__(self):\n",
    "    return self.__repr__()\n",
    "\n",
    "  def __repr__(self):\n",
    "    s = \"\"\n",
    "    s += \"qas_id: %s\" % (tokenization.printable_text(self.qas_id))\n",
    "    s += \", question_text: %s\" % (\n",
    "        tokenization.printable_text(self.question_text))\n",
    "    s += \", paragraph_text: [%s]\" % (\" \".join(self.paragraph_text))\n",
    "    if self.start_position:\n",
    "      s += \", start_position: %d\" % (self.start_position)\n",
    "    if self.start_position:\n",
    "      s += \", end_position: %d\" % (self.end_position)\n",
    "    if self.start_position:\n",
    "      s += \", is_impossible: %r\" % (self.is_impossible)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "  \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               unique_id,\n",
    "               example_index,\n",
    "               doc_span_index,\n",
    "               tok_start_to_orig_index,\n",
    "               tok_end_to_orig_index,\n",
    "               token_is_max_context,\n",
    "               tokens,\n",
    "               input_ids,\n",
    "               input_mask,\n",
    "               segment_ids,\n",
    "               paragraph_len,\n",
    "               p_mask=None,\n",
    "               cls_index=None,\n",
    "               start_position=None,\n",
    "               end_position=None,\n",
    "               is_impossible=None):\n",
    "    self.unique_id = unique_id\n",
    "    self.example_index = example_index\n",
    "    self.doc_span_index = doc_span_index\n",
    "    self.tok_start_to_orig_index = tok_start_to_orig_index\n",
    "    self.tok_end_to_orig_index = tok_end_to_orig_index\n",
    "    self.token_is_max_context = token_is_max_context\n",
    "    self.tokens = tokens\n",
    "    self.input_ids = input_ids\n",
    "    self.input_mask = input_mask\n",
    "    self.segment_ids = segment_ids\n",
    "    self.paragraph_len = paragraph_len\n",
    "    self.start_position = start_position\n",
    "    self.end_position = end_position\n",
    "    self.is_impossible = is_impossible\n",
    "    self.p_mask = p_mask\n",
    "    self.cls_index = cls_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_squad(question: str, paragraph: str):\n",
    "    qas_id = \"1234\"\n",
    "    orig_answer_text = None\n",
    "    start_position = None\n",
    "    is_impossible = None\n",
    "    examples = []\n",
    "    example = SquadExample(\n",
    "            qas_id=qas_id,\n",
    "            question_text=question,\n",
    "            paragraph_text=paragraph,\n",
    "            orig_answer_text=orig_answer_text,\n",
    "            start_position=start_position,\n",
    "            is_impossible=is_impossible)\n",
    "    examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_is_max_context(doc_spans, cur_span_index, position):\n",
    "  \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n",
    "\n",
    "  # Because of the sliding window approach taken to scoring documents, a single\n",
    "  # token can appear in multiple documents. E.g.\n",
    "  #  Doc: the man went to the store and bought a gallon of milk\n",
    "  #  Span A: the man went to the\n",
    "  #  Span B: to the store and bought\n",
    "  #  Span C: and bought a gallon of\n",
    "  #  ...\n",
    "  #\n",
    "  # Now the word 'bought' will have two scores from spans B and C. We only\n",
    "  # want to consider the score with \"maximum context\", which we define as\n",
    "  # the *minimum* of its left and right context (the *sum* of left and\n",
    "  # right context will always be the same, of course).\n",
    "  #\n",
    "  # In the example the maximum context for 'bought' would be span C since\n",
    "  # it has 1 left context and 3 right context, while span B has 4 left context\n",
    "  # and 0 right context.\n",
    "  best_score = None\n",
    "  best_span_index = None\n",
    "  for (span_index, doc_span) in enumerate(doc_spans):\n",
    "    end = doc_span.start + doc_span.length - 1\n",
    "    if position < doc_span.start:\n",
    "      continue\n",
    "    if position > end:\n",
    "      continue\n",
    "    num_left_context = position - doc_span.start\n",
    "    num_right_context = end - position\n",
    "    score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
    "    if best_score is None or score > best_score:\n",
    "      best_score = score\n",
    "      best_span_index = span_index\n",
    "\n",
    "  return cur_span_index == best_span_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_index(index, pos, m=None, is_start=True):\n",
    "  \"\"\"Converts index.\"\"\"\n",
    "  if index[pos] is not None:\n",
    "    return index[pos]\n",
    "  n = len(index)\n",
    "  rear = pos\n",
    "  while rear < n - 1 and index[rear] is None:\n",
    "    rear += 1\n",
    "  front = pos\n",
    "  while front > 0 and index[front] is None:\n",
    "    front -= 1\n",
    "  assert index[front] is not None or index[rear] is not None\n",
    "  if index[front] is None:\n",
    "    if index[rear] >= 1:\n",
    "      if is_start:\n",
    "        return 0\n",
    "      else:\n",
    "        return index[rear] - 1\n",
    "    return index[rear]\n",
    "  if index[rear] is None:\n",
    "    if m is not None and index[front] < m - 1:\n",
    "      if is_start:\n",
    "        return index[front] + 1\n",
    "      else:\n",
    "        return m - 1\n",
    "    return index[front]\n",
    "  if is_start:\n",
    "    if index[rear] > index[front] + 1:\n",
    "      return index[front] + 1\n",
    "    else:\n",
    "      return index[rear]\n",
    "  else:\n",
    "    if index[rear] > index[front] + 1:\n",
    "      return index[rear] - 1\n",
    "    else:\n",
    "      return index[front]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, tokenizer, max_seq_length,\n",
    "                                 doc_stride, max_query_length, is_training=False):\n",
    "  \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "  cnt_pos, cnt_neg = 0, 0\n",
    "  base_id = 1000000000\n",
    "  unique_id = base_id\n",
    "  max_n, max_m = 1024, 1024\n",
    "  f = np.zeros((max_n, max_m), dtype=np.float32)\n",
    "  \n",
    "  features = []\n",
    "\n",
    "  for (example_index, example) in enumerate(examples):\n",
    "\n",
    "    query_tokens = tokenization.encode_ids(\n",
    "        tokenizer.sp_model,\n",
    "        tokenization.preprocess_text(\n",
    "            example.question_text, lower=do_lower_case))\n",
    "\n",
    "    if len(query_tokens) > max_query_length:\n",
    "      query_tokens = query_tokens[0:max_query_length]\n",
    "\n",
    "    paragraph_text = example.paragraph_text\n",
    "    para_tokens = tokenization.encode_pieces(\n",
    "        tokenizer.sp_model,\n",
    "        tokenization.preprocess_text(\n",
    "            example.paragraph_text, lower=do_lower_case),\n",
    "        return_unicode=False)\n",
    "\n",
    "    para_tokens_ = []\n",
    "    for para_token in para_tokens:\n",
    "      if type(para_token) == bytes:\n",
    "        para_token = para_token.decode(\"utf-8\")\n",
    "      para_tokens_.append(para_token)\n",
    "    para_tokens = para_tokens_\n",
    "\n",
    "    chartok_to_tok_index = []\n",
    "    tok_start_to_chartok_index = []\n",
    "    tok_end_to_chartok_index = []\n",
    "    char_cnt = 0\n",
    "    for i, token in enumerate(para_tokens):\n",
    "      chartok_to_tok_index.extend([i] * len(token))\n",
    "      tok_start_to_chartok_index.append(char_cnt)\n",
    "      char_cnt += len(token)\n",
    "      tok_end_to_chartok_index.append(char_cnt - 1)\n",
    "\n",
    "    tok_cat_text = \"\".join(para_tokens).replace(tokenization.SPIECE_UNDERLINE.decode(\"utf-8\"), \" \")\n",
    "    n, m = len(paragraph_text), len(tok_cat_text)\n",
    "\n",
    "    if n > max_n or m > max_m:\n",
    "      max_n = max(n, max_n)\n",
    "      max_m = max(m, max_m)\n",
    "      f = np.zeros((max_n, max_m), dtype=np.float32)\n",
    "\n",
    "    g = {}\n",
    "\n",
    "    def _lcs_match(max_dist, n=n, m=m):\n",
    "      \"\"\"Longest-common-substring algorithm.\"\"\"\n",
    "      f.fill(0)\n",
    "      g.clear()\n",
    "\n",
    "      ### longest common sub sequence\n",
    "      # f[i, j] = max(f[i - 1, j], f[i, j - 1], f[i - 1, j - 1] + match(i, j))\n",
    "      for i in range(n):\n",
    "\n",
    "        # note(zhiliny):\n",
    "        # unlike standard LCS, this is specifically optimized for the setting\n",
    "        # because the mismatch between sentence pieces and original text will\n",
    "        # be small\n",
    "        for j in range(i - max_dist, i + max_dist):\n",
    "          if j >= m or j < 0: continue\n",
    "\n",
    "          if i > 0:\n",
    "            g[(i, j)] = 0\n",
    "            f[i, j] = f[i - 1, j]\n",
    "\n",
    "          if j > 0 and f[i, j - 1] > f[i, j]:\n",
    "            g[(i, j)] = 1\n",
    "            f[i, j] = f[i, j - 1]\n",
    "\n",
    "          f_prev = f[i - 1, j - 1] if i > 0 and j > 0 else 0\n",
    "          if (tokenization.preprocess_text(\n",
    "              paragraph_text[i], lower=do_lower_case,\n",
    "              remove_space=False) == tok_cat_text[j]\n",
    "              and f_prev + 1 > f[i, j]):\n",
    "            g[(i, j)] = 2\n",
    "            f[i, j] = f_prev + 1\n",
    "\n",
    "    max_dist = abs(n - m) + 5\n",
    "    for _ in range(2):\n",
    "      _lcs_match(max_dist)\n",
    "      if f[n - 1, m - 1] > 0.8 * n: break\n",
    "      max_dist *= 2\n",
    "\n",
    "    orig_to_chartok_index = [None] * n\n",
    "    chartok_to_orig_index = [None] * m\n",
    "    i, j = n - 1, m - 1\n",
    "    while i >= 0 and j >= 0:\n",
    "      if (i, j) not in g: break\n",
    "      if g[(i, j)] == 2:\n",
    "        orig_to_chartok_index[i] = j\n",
    "        chartok_to_orig_index[j] = i\n",
    "        i, j = i - 1, j - 1\n",
    "      elif g[(i, j)] == 1:\n",
    "        j = j - 1\n",
    "      else:\n",
    "        i = i - 1\n",
    "\n",
    "    if (all(v is None for v in orig_to_chartok_index) or\n",
    "        f[n - 1, m - 1] < 0.8 * n):\n",
    "      logging.info(\"MISMATCH DETECTED!\")\n",
    "      continue\n",
    "\n",
    "    tok_start_to_orig_index = []\n",
    "    tok_end_to_orig_index = []\n",
    "    for i in range(len(para_tokens)):\n",
    "      start_chartok_pos = tok_start_to_chartok_index[i]\n",
    "      end_chartok_pos = tok_end_to_chartok_index[i]\n",
    "      start_orig_pos = _convert_index(chartok_to_orig_index, start_chartok_pos,\n",
    "                                      n, is_start=True)\n",
    "      end_orig_pos = _convert_index(chartok_to_orig_index, end_chartok_pos,\n",
    "                                    n, is_start=False)\n",
    "\n",
    "      tok_start_to_orig_index.append(start_orig_pos)\n",
    "      tok_end_to_orig_index.append(end_orig_pos)\n",
    "\n",
    "    if not is_training:\n",
    "      tok_start_position = tok_end_position = None\n",
    "\n",
    "    if is_training and example.is_impossible:\n",
    "      tok_start_position = 0\n",
    "      tok_end_position = 0\n",
    "\n",
    "    if is_training and not example.is_impossible:\n",
    "      start_position = example.start_position\n",
    "      end_position = start_position + len(example.orig_answer_text) - 1\n",
    "\n",
    "      start_chartok_pos = _convert_index(orig_to_chartok_index, start_position,\n",
    "                                         is_start=True)\n",
    "      tok_start_position = chartok_to_tok_index[start_chartok_pos]\n",
    "\n",
    "      end_chartok_pos = _convert_index(orig_to_chartok_index, end_position,\n",
    "                                       is_start=False)\n",
    "      tok_end_position = chartok_to_tok_index[end_chartok_pos]\n",
    "      assert tok_start_position <= tok_end_position\n",
    "\n",
    "    def _piece_to_id(x):\n",
    "      if six.PY2 and isinstance(x, six.text_type):\n",
    "        x = six.ensure_binary(x, \"utf-8\")\n",
    "      return tokenizer.sp_model.PieceToId(x)\n",
    "\n",
    "    all_doc_tokens = list(map(_piece_to_id, para_tokens))\n",
    "\n",
    "    # The -3 accounts for [CLS], [SEP] and [SEP]\n",
    "    max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
    "\n",
    "    doc_spans = []\n",
    "    start_offset = 0\n",
    "    while start_offset < len(all_doc_tokens):\n",
    "      length = len(all_doc_tokens) - start_offset\n",
    "      if length > max_tokens_for_doc:\n",
    "        length = max_tokens_for_doc\n",
    "      doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "      if start_offset + length == len(all_doc_tokens):\n",
    "        break\n",
    "      start_offset += min(length, doc_stride)\n",
    "\n",
    "    for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "      tokens = []\n",
    "      token_is_max_context = {}\n",
    "      segment_ids = []\n",
    "      p_mask = []\n",
    "      cls_index = 0\n",
    "\n",
    "      cur_tok_start_to_orig_index = []\n",
    "      cur_tok_end_to_orig_index = []\n",
    "\n",
    "      tokens.append(tokenizer.sp_model.PieceToId(\"[CLS]\"))\n",
    "      segment_ids.append(0)\n",
    "      p_mask.append(0)\n",
    "      for token in query_tokens:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "        p_mask.append(1)\n",
    "      tokens.append(tokenizer.sp_model.PieceToId(\"[SEP]\"))\n",
    "      segment_ids.append(0)\n",
    "      p_mask.append(1)\n",
    "\n",
    "      for i in range(doc_span.length):\n",
    "        split_token_index = doc_span.start + i\n",
    "\n",
    "        cur_tok_start_to_orig_index.append(\n",
    "            tok_start_to_orig_index[split_token_index])\n",
    "        cur_tok_end_to_orig_index.append(\n",
    "            tok_end_to_orig_index[split_token_index])\n",
    "\n",
    "        is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
    "                                               split_token_index)\n",
    "        token_is_max_context[len(tokens)] = is_max_context\n",
    "        tokens.append(all_doc_tokens[split_token_index])\n",
    "        segment_ids.append(1)\n",
    "        p_mask.append(0)\n",
    "      tokens.append(tokenizer.sp_model.PieceToId(\"[SEP]\"))\n",
    "      segment_ids.append(1)\n",
    "      p_mask.append(1)\n",
    "\n",
    "      paragraph_len = len(tokens)\n",
    "      input_ids = tokens\n",
    "\n",
    "      # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "      # tokens are attended to.\n",
    "      input_mask = [1] * len(input_ids)\n",
    "\n",
    "      # Zero-pad up to the sequence length.\n",
    "      while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "        p_mask.append(1)\n",
    "\n",
    "      assert len(input_ids) == max_seq_length\n",
    "      assert len(input_mask) == max_seq_length\n",
    "      assert len(segment_ids) == max_seq_length\n",
    "\n",
    "      span_is_impossible = example.is_impossible\n",
    "      start_position = None\n",
    "      end_position = None\n",
    "      if is_training and not span_is_impossible:\n",
    "        # For training, if our document chunk does not contain an annotation\n",
    "        # we throw it out, since there is nothing to predict.\n",
    "        doc_start = doc_span.start\n",
    "        doc_end = doc_span.start + doc_span.length - 1\n",
    "        out_of_span = False\n",
    "        if not (tok_start_position >= doc_start and\n",
    "                tok_end_position <= doc_end):\n",
    "          out_of_span = True\n",
    "        if out_of_span:\n",
    "          # continue\n",
    "          start_position = 0\n",
    "          end_position = 0\n",
    "          span_is_impossible = True\n",
    "        else:\n",
    "          doc_offset = len(query_tokens) + 2\n",
    "          start_position = tok_start_position - doc_start + doc_offset\n",
    "          end_position = tok_end_position - doc_start + doc_offset\n",
    "\n",
    "      if is_training and span_is_impossible:\n",
    "        start_position = cls_index\n",
    "        end_position = cls_index\n",
    "\n",
    "      if is_training:\n",
    "        feat_example_index = None\n",
    "      else:\n",
    "        feat_example_index = example_index\n",
    "\n",
    "      feature = InputFeatures(\n",
    "          unique_id=unique_id,\n",
    "          example_index=feat_example_index,\n",
    "          doc_span_index=doc_span_index,\n",
    "          tok_start_to_orig_index=cur_tok_start_to_orig_index,\n",
    "          tok_end_to_orig_index=cur_tok_end_to_orig_index,\n",
    "          token_is_max_context=token_is_max_context,\n",
    "          tokens=[tokenizer.sp_model.IdToPiece(x) for x in tokens],\n",
    "          input_ids=input_ids,\n",
    "          input_mask=input_mask,\n",
    "          segment_ids=segment_ids,\n",
    "          paragraph_len=paragraph_len,\n",
    "          start_position=start_position,\n",
    "          end_position=end_position,\n",
    "          is_impossible=span_is_impossible,\n",
    "          p_mask=p_mask,\n",
    "          cls_index=cls_index)\n",
    "\n",
    "      # Run callback\n",
    "      features.append(feature)\n",
    "    \n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "albert_config = AlbertConfig.from_json_file(albert_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_model = ALBertQAModel(albert_config, max_seq_length, init_checkpoint=None, start_n_top=5, end_n_top=5, dropout=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8d04c18da0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_model.load_weights(\"squad_out_v2.0/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = tf.train.latest_checkpoint(model_dir)\n",
    "# checkpoint = tf.train.Checkpoint(model=squad_model)\n",
    "# checkpoint.restore(checkpoint_path).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_results_v2(predictions):\n",
    "    \"\"\"Converts multi-replica predictions to RawResult.\"\"\"\n",
    "    for unique_ids, start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits in zip(predictions['unique_ids'],\n",
    "                                                    predictions['start_top_log_probs'],\n",
    "                                                    predictions['start_top_index'],\n",
    "                                                    predictions['end_top_log_probs'],\n",
    "                                                    predictions['end_top_index'],\n",
    "                                                    predictions['cls_logits']):\n",
    "        return RawResultV2(\n",
    "                unique_id=unique_ids.numpy(),\n",
    "                start_top_log_probs=start_top_log_probs.numpy().tolist(),\n",
    "                start_top_index=start_top_index.numpy().tolist(),\n",
    "                end_top_log_probs=end_top_log_probs.numpy().tolist(),\n",
    "                end_top_index=end_top_index.numpy().tolist(),\n",
    "                cls_logits=cls_logits.numpy().tolist()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_predictions_v2(result_dict, cls_dict, all_examples,\n",
    "                              all_features, all_results, n_best_size,\n",
    "                              max_answer_length, start_n_top, end_n_top):\n",
    "  \"\"\"accumulate predictions for each positions in a dictionary.\"\"\"\n",
    "\n",
    "  example_index_to_features = collections.defaultdict(list)\n",
    "  for feature in all_features:\n",
    "    example_index_to_features[feature.example_index].append(feature)\n",
    "\n",
    "  unique_id_to_result = {}\n",
    "  for result in all_results:\n",
    "    unique_id_to_result[result.unique_id] = result\n",
    "\n",
    "  for (example_index, example) in enumerate(all_examples):\n",
    "    if example_index not in result_dict:\n",
    "      result_dict[example_index] = {}\n",
    "    features = example_index_to_features[example_index]\n",
    "\n",
    "    # keep track of the minimum score of null start+end of position 0\n",
    "    score_null = 1000000  # large and positive\n",
    "\n",
    "    for (feature_index, feature) in enumerate(features):\n",
    "      if feature.unique_id not in result_dict[example_index]:\n",
    "        result_dict[example_index][feature.unique_id] = {}\n",
    "      result = unique_id_to_result[feature.unique_id]\n",
    "      cur_null_score = result.cls_logits\n",
    "\n",
    "      # if we could have irrelevant answers, get the min score of irrelevant\n",
    "      score_null = min(score_null, cur_null_score)\n",
    "\n",
    "      doc_offset = feature.tokens.index(\"[SEP]\") + 1\n",
    "      for i in range(start_n_top):\n",
    "        for j in range(end_n_top):\n",
    "          start_log_prob = result.start_top_log_probs[i]\n",
    "          start_index = result.start_top_index[i]\n",
    "\n",
    "          j_index = i * end_n_top + j\n",
    "\n",
    "          end_log_prob = result.end_top_log_probs[j_index]\n",
    "          end_index = result.end_top_index[j_index]\n",
    "          # We could hypothetically create invalid predictions, e.g., predict\n",
    "          # that the start of the span is in the question. We throw out all\n",
    "          # invalid predictions.\n",
    "          if start_index - doc_offset >= len(feature.tok_start_to_orig_index):\n",
    "            continue\n",
    "          if start_index - doc_offset < 0:\n",
    "            continue\n",
    "          if end_index - doc_offset >= len(feature.tok_end_to_orig_index):\n",
    "            continue\n",
    "          if not feature.token_is_max_context.get(start_index, False):\n",
    "            continue\n",
    "          if end_index < start_index:\n",
    "            continue\n",
    "          length = end_index - start_index + 1\n",
    "          if length > max_answer_length:\n",
    "            continue\n",
    "          start_idx = start_index - doc_offset\n",
    "          end_idx = end_index - doc_offset\n",
    "          if (start_idx, end_idx) not in result_dict[example_index][feature.unique_id]:\n",
    "            result_dict[example_index][feature.unique_id][(start_idx, end_idx)] = []\n",
    "          result_dict[example_index][feature.unique_id][(start_idx, end_idx)].append((start_log_prob, end_log_prob))\n",
    "    if example_index not in cls_dict:\n",
    "      cls_dict[example_index] = []\n",
    "    cls_dict[example_index].append(score_null)\n",
    "  return (result_dict,cls_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_model.weights.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_softmax(scores):\n",
    "  \"\"\"Compute softmax probability over raw logits.\"\"\"\n",
    "  if not scores:\n",
    "    return []\n",
    "\n",
    "  max_score = None\n",
    "  for score in scores:\n",
    "    if max_score is None or score > max_score:\n",
    "      max_score = score\n",
    "\n",
    "  exp_scores = []\n",
    "  total_sum = 0.0\n",
    "  for score in scores:\n",
    "    x = math.exp(score - max_score)\n",
    "    exp_scores.append(x)\n",
    "    total_sum += x\n",
    "\n",
    "  probs = []\n",
    "  for score in exp_scores:\n",
    "    probs.append(score / total_sum)\n",
    "  return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions_v2(all_examples, all_features, all_results, n_best_size=20,\n",
    "                      max_answer_length=30,start_n_top=5, end_n_top=5):\n",
    "  \"\"\"Writes final predictions to the json file and log-odds of null if needed.\"\"\"\n",
    "  \n",
    "  result_dict, cls_dict = {},{}\n",
    "  result_dict, cls_dict = accumulate_predictions_v2(result_dict,cls_dict,all_examples,\n",
    "                                    all_features,all_results,n_best_size,max_answer_length,\n",
    "                                    start_n_top,end_n_top)\n",
    "                                    \n",
    "  example_index_to_features = collections.defaultdict(list)\n",
    "  for feature in all_features:\n",
    "    example_index_to_features[feature.example_index].append(feature)\n",
    "\n",
    "  unique_id_to_result = {}\n",
    "  for result in all_results:\n",
    "    unique_id_to_result[result.unique_id] = result\n",
    "\n",
    "  all_predictions = collections.OrderedDict()\n",
    "  all_nbest_json = collections.OrderedDict()\n",
    "  scores_diff_json = collections.OrderedDict()\n",
    "\n",
    "  for (example_index, example) in enumerate(all_examples):\n",
    "    features = example_index_to_features[example_index]\n",
    "\n",
    "    prelim_predictions = []\n",
    "    # keep track of the minimum score of null start+end of position 0\n",
    "    # score_null = 1000000  # large and positive\n",
    "\n",
    "    for (feature_index, feature) in enumerate(features):\n",
    "      for ((start_idx, end_idx), logprobs) in \\\n",
    "        result_dict[example_index][feature.unique_id].items():\n",
    "        start_log_prob = 0\n",
    "        end_log_prob = 0\n",
    "        for logprob in logprobs:\n",
    "          start_log_prob += logprob[0]\n",
    "          end_log_prob += logprob[1]\n",
    "        prelim_predictions.append(\n",
    "            _PrelimPredictionV2(\n",
    "                feature_index=feature_index,\n",
    "                start_index=start_idx,\n",
    "                end_index=end_idx,\n",
    "                start_log_prob=start_log_prob / len(logprobs),\n",
    "                end_log_prob=end_log_prob / len(logprobs)))\n",
    "\n",
    "    prelim_predictions = sorted(\n",
    "        prelim_predictions,\n",
    "        key=lambda x: (x.start_log_prob + x.end_log_prob),\n",
    "        reverse=True)\n",
    "\n",
    "    seen_predictions = {}\n",
    "    nbest = []\n",
    "    for pred in prelim_predictions:\n",
    "      if len(nbest) >= n_best_size:\n",
    "        break\n",
    "      feature = features[pred.feature_index]\n",
    "\n",
    "      tok_start_to_orig_index = feature.tok_start_to_orig_index\n",
    "      tok_end_to_orig_index = feature.tok_end_to_orig_index\n",
    "      start_orig_pos = tok_start_to_orig_index[pred.start_index]\n",
    "      end_orig_pos = tok_end_to_orig_index[pred.end_index]\n",
    "\n",
    "      paragraph_text = example.paragraph_text\n",
    "      final_text = paragraph_text[start_orig_pos: end_orig_pos + 1].strip()\n",
    "\n",
    "      if final_text in seen_predictions:\n",
    "        continue\n",
    "\n",
    "      seen_predictions[final_text] = True\n",
    "\n",
    "      nbest.append(\n",
    "          _NbestPredictionV2(\n",
    "              text=final_text,\n",
    "              start_log_prob=pred.start_log_prob,\n",
    "              end_log_prob=pred.end_log_prob,\n",
    "              start_index=pred.start_index,\n",
    "              end_index=pred.end_index))\n",
    "\n",
    "    # In very rare edge cases we could have no valid predictions. So we\n",
    "    # just create a nonce prediction in this case to avoid failure.\n",
    "    if not nbest:\n",
    "      nbest.append(\n",
    "          _NbestPredictionV2(\n",
    "              text=\"\",\n",
    "              start_log_prob=-1e6,\n",
    "              end_log_prob=-1e6,\n",
    "              start_index=-1,\n",
    "              end_index=-1))\n",
    "\n",
    "    total_scores = []\n",
    "    best_non_null_entry = None\n",
    "    for entry in nbest:\n",
    "      total_scores.append(entry.start_log_prob + entry.end_log_prob)\n",
    "      if not best_non_null_entry:\n",
    "        best_non_null_entry = entry\n",
    "\n",
    "    probs = _compute_softmax(total_scores)\n",
    "\n",
    "    nbest_json = []\n",
    "    for (i, entry) in enumerate(nbest):\n",
    "      output = collections.OrderedDict()\n",
    "      output[\"text\"] = entry.text\n",
    "      output[\"probability\"] = probs[i]\n",
    "      output[\"start_log_prob\"] = entry.start_log_prob\n",
    "      output[\"end_log_prob\"] = entry.end_log_prob\n",
    "      output[\"start_index\"] = entry.start_index\n",
    "      output[\"end_index\"] = entry.end_index + 1\n",
    "      nbest_json.append(output)\n",
    "\n",
    "    assert len(nbest_json) >= 1\n",
    "    assert best_non_null_entry is not None\n",
    "\n",
    "    score_diff = sum(cls_dict[example_index]) / len(cls_dict[example_index])\n",
    "    scores_diff_json[example.qas_id] = score_diff\n",
    "    # predict null answers when null threshold is provided\n",
    "    if null_score_diff_threshold is None or score_diff < null_score_diff_threshold:\n",
    "      all_predictions[example.qas_id] = best_non_null_entry.text\n",
    "    else:\n",
    "      all_predictions[example.qas_id] = \"\"\n",
    "\n",
    "    all_nbest_json[example.qas_id] = nbest_json\n",
    "    assert len(nbest_json) >= 1\n",
    "  return all_predictions,all_nbest_json    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"Closely related fields in theoretical computer science are analysis of algorithms and computability theory. A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem. More precisely, it tries to classify problems that can or cannot be solved with appropriately restricted resources. In turn, imposing restrictions on the available resources is what distinguishes computational complexity from computability theory: the latter theory asks what kind of problems can, in principle, be solved algorithmically.\"\n",
    "\n",
    "q = 'What two fields of theoretical computer science closely mirror computational complexity theory?'\n",
    "\n",
    "examples = convert_to_squad(q,doc)\n",
    "\n",
    "features = convert_examples_to_features(examples,tokenizer,max_seq_length=384,doc_stride=128,max_query_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for X in features:\n",
    "    x = {\"unique_ids\" : tf.convert_to_tensor([X.unique_id],dtype=tf.int64),\n",
    "         \"input_ids\" : tf.convert_to_tensor([X.input_ids],dtype=tf.int64),\n",
    "         \"input_mask\" : tf.convert_to_tensor([X.input_mask],dtype=tf.int64),\n",
    "         \"segment_ids\" : tf.convert_to_tensor([X.segment_ids],dtype=tf.int64),\n",
    "         \"cls_index\" : tf.convert_to_tensor([X.cls_index],dtype=tf.int64),\n",
    "         \"p_mask\" : tf.convert_to_tensor([X.p_mask],dtype=tf.float32)\n",
    "    }\n",
    "    y = squad_model(x,training=False)\n",
    "    unique_ids, start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits = y\n",
    "    predictions = dict(unique_ids=unique_ids,\n",
    "            start_top_log_probs=start_top_log_probs,\n",
    "            start_top_index=start_top_index,\n",
    "            end_top_log_probs=end_top_log_probs,\n",
    "            end_top_index=end_top_index,\n",
    "            cls_logits=cls_logits)\n",
    "    all_results.append(get_raw_results_v2(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('1234', 'analysis of algorithms and computability theory')]),\n",
       " OrderedDict([('1234',\n",
       "               [OrderedDict([('text',\n",
       "                              'analysis of algorithms and computability theory'),\n",
       "                             ('probability', 0.9944961576562703),\n",
       "                             ('start_log_prob', -0.012674023397266865),\n",
       "                             ('end_log_prob', -0.0032195420935750008),\n",
       "                             ('start_index', 8),\n",
       "                             ('end_index', 16)]),\n",
       "                OrderedDict([('text',\n",
       "                              'analysis of algorithms and computability theory.'),\n",
       "                             ('probability', 0.0029161772185747484),\n",
       "                             ('start_log_prob', -0.012674023397266865),\n",
       "                             ('end_log_prob', -5.835182189941406),\n",
       "                             ('start_index', 8),\n",
       "                             ('end_index', 17)]),\n",
       "                OrderedDict([('text', 'analysis of algorithms'),\n",
       "                             ('probability', 0.0013619366827742594),\n",
       "                             ('start_log_prob', -6.602829456329346),\n",
       "                             ('end_log_prob', -0.006392625626176596),\n",
       "                             ('start_index', 21),\n",
       "                             ('end_index', 24)]),\n",
       "                OrderedDict([('text', 'algorithms and computability theory'),\n",
       "                             ('probability', 0.0009337469632213863),\n",
       "                             ('start_log_prob', -6.9539923667907715),\n",
       "                             ('end_log_prob', -0.0326872281730175),\n",
       "                             ('start_index', 10),\n",
       "                             ('end_index', 16)]),\n",
       "                OrderedDict([('text',\n",
       "                              'analysis of algorithms and computability'),\n",
       "                             ('probability', 0.00013229397722861404),\n",
       "                             ('start_log_prob', -0.012674023397266865),\n",
       "                             ('end_log_prob', -8.928184509277344),\n",
       "                             ('start_index', 8),\n",
       "                             ('end_index', 15)]),\n",
       "                OrderedDict([('text',\n",
       "                              'Closely related fields in theoretical computer science are analysis of algorithms and computability theory.'),\n",
       "                             ('probability', 8.410672676238626e-05),\n",
       "                             ('start_log_prob', -8.94800853729248),\n",
       "                             ('end_log_prob', -0.44578999280929565),\n",
       "                             ('start_index', 0),\n",
       "                             ('end_index', 17)]),\n",
       "                OrderedDict([('text',\n",
       "                              'Closely related fields in theoretical computer science are analysis of algorithms and computability theory'),\n",
       "                             ('probability', 3.5307857542054354e-05),\n",
       "                             ('start_log_prob', -8.94800853729248),\n",
       "                             ('end_log_prob', -1.3137710094451904),\n",
       "                             ('start_index', 0),\n",
       "                             ('end_index', 16)]),\n",
       "                OrderedDict([('text', 'algorithms and computability theory.'),\n",
       "                             ('probability', 2.373785724323249e-05),\n",
       "                             ('start_log_prob', -6.9539923667907715),\n",
       "                             ('end_log_prob', -3.7048215866088867),\n",
       "                             ('start_index', 10),\n",
       "                             ('end_index', 17)]),\n",
       "                OrderedDict([('text',\n",
       "                              'analysis of algorithms and computational complexity theory'),\n",
       "                             ('probability', 4.434479219335953e-06),\n",
       "                             ('start_log_prob', -6.602829456329346),\n",
       "                             ('end_log_prob', -5.733645439147949),\n",
       "                             ('start_index', 21),\n",
       "                             ('end_index', 28)]),\n",
       "                OrderedDict([('text', 'algorithms'),\n",
       "                             ('probability', 3.5117877329153127e-06),\n",
       "                             ('start_log_prob', -6.9539923667907715),\n",
       "                             ('end_log_prob', -5.615767478942871),\n",
       "                             ('start_index', 10),\n",
       "                             ('end_index', 11)]),\n",
       "                OrderedDict([('text', 'Closely related fields'),\n",
       "                             ('probability', 3.2942051826667184e-06),\n",
       "                             ('start_log_prob', -8.94800853729248),\n",
       "                             ('end_log_prob', -3.685711622238159),\n",
       "                             ('start_index', 0),\n",
       "                             ('end_index', 3)]),\n",
       "                OrderedDict([('text', 'algorithms and computability'),\n",
       "                             ('probability', 3.2500788238689944e-06),\n",
       "                             ('start_log_prob', -6.9539923667907715),\n",
       "                             ('end_log_prob', -5.69321346282959),\n",
       "                             ('start_index', 10),\n",
       "                             ('end_index', 15)]),\n",
       "                OrderedDict([('text',\n",
       "                              'Closely related fields in theoretical computer science are analysis of algorithms and computability'),\n",
       "                             ('probability', 1.0604412403939226e-06),\n",
       "                             ('start_log_prob', -8.94800853729248),\n",
       "                             ('end_log_prob', -4.8191914558410645),\n",
       "                             ('start_index', 0),\n",
       "                             ('end_index', 15)]),\n",
       "                OrderedDict([('text', 'analysis'),\n",
       "                             ('probability', 9.840681834660751e-07),\n",
       "                             ('start_log_prob', -6.602829456329346),\n",
       "                             ('end_log_prob', -7.2391157150268555),\n",
       "                             ('start_index', 21),\n",
       "                             ('end_index', 22)])])]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_predictions_v2(examples,features,all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
